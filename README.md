# Paso-a-PAso-del-Word2vec
 En este proyecto se presenta un ejemplo de word2vec desde el preprocesamiento del corpus, a su conversión en one-hot, a enteros con el fin de obtener el conjunto de entrenamiento. Este conjunto consiste de las palabras centro u objetivo con sus respectivas palabras de contexto. Luego se realiza el embedding matricial de una entrada x, con los embedding de los ejemplos de entrenamiento con el fin de bajar la dimensionalidad del vocabulario al embedding reducido (aplicando embudo). Este embedding reducido luego es expandido para que através de la función Softwax se probabilice la relación de las palabras centro con las palabras contextos. En resumen, esta es una red de tres capas, en donde en la capa hidden se implementan la función softmax que asigna una distribución de probailidad que modela el acercamiento de la palabra centro con sus palabras contextuales más cercanas.
